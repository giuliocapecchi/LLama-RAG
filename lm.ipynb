{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliocapecchi/LM-project/blob/main/lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Pipeline on PDFs with Limited GPU Requirements\n",
        "\n",
        "In this project, we aim to build a **Retrieval-Augmented Generation (RAG)** pipeline optimized for **limited GPU environments**. The goal is to combine the power of *dense retrieval-based methods* with the flexibility of generative models, while ensuring the system remains efficient enough to run on medium-tier laptops with GPUs.\n",
        "\n",
        "A RAG pipeline consists of two main stages: **retrieval** and **generation**. The entire process can be divided into **3 key steps**:\n",
        "\n",
        "1. **Generation of document embeddings**  \n",
        "   In this step, document embeddings are generated from a *corpus* using an embedding model. Each document is encoded into a dense vector representation, capturing semantic information.\n",
        "\n",
        "2. **Document retrieval**  \n",
        "   Relevant documents are fetched from the corpus based on the input query. This is achieved by utilizing the generated embeddings and calculating similarity with the query's embedding to retrieve the most relevant documents.\n",
        "\n",
        "3. **Output generation**  \n",
        "   The retrieved documents are then passed to a **generative model**, which produces contextually relevant responses based on the information extracted from the documents.\n",
        "\n",
        "By leveraging lightweight models and optimizing for efficiency, this RAG pipeline delivers powerful **AI-driven results** even on hardware with **limited resources**.\n",
        "\n",
        "Finally, a **Gradio interface** is provided, allowing users to interact with the system and \"chat\" with the documents they provide, offering a seamless experience for exploring the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NEhwjiDjaime"
      },
      "outputs": [],
      "source": [
        "#%pip install -q --progress-bar torch huggingface_hub python-dotenv transformers sentence-transformers pymupdf langchain langchain-community langchain-huggingface chromadb tqdm unidecode gradio bitsandbytes seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GiueDXQqaimg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "from dotenv import load_dotenv\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import gradio as gr\n",
        "from unidecode import unidecode\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hardware requirements and constraints\n",
        "\n",
        "Let's find out what hardware we've got available to see what kind of model(s) we'll be able to load.\n",
        "\n",
        "> **Note:** You can also check this with the `!nvidia-smi` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get GPU available memory\n",
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
        "print(f\"Available GPU memory: {gpu_memory_gb} GB\")\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course, depending on the provided harware, better models can be utilized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checking local GPU memory availability\n",
        "\n",
        "Let's first analyze how we decided the model to use for this project. This notebook was primarily run and tested locally on a **laptop** with 16GB of RAM and an NVIDIA RTX 3070 laptop GPU (8GB of VRAM). The main goal was to create a pipeline that could efficiently run on this portable device, leveraging the benefits of GPUs and CUDA for AI tasks while ensuring that the performance and capabilities did not feel lacking compared to larger models.\n",
        "\n",
        "We will need two main ingredients:\n",
        "- An *embedder* model, that calculates dense embeddings from documents\n",
        "- An *LLM*, that provides output given user's queries and the retrieved documents\n",
        "\n",
        "In their dedicated sections we will uncover the choiches made for both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load our PDF and start producing chunks\n",
        "\n",
        "Let's now start by loading a pdf file and extracting chunks from it. These chunks' **quality** is important, since these will be essentially the *documents* on which we will compute the embeddings on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBaOxo4gaimg",
        "outputId": "bff442a7-eb21-4a3c-fe51-a3788fe4dfbb"
      },
      "outputs": [],
      "source": [
        "PDF_NAME = \"IR Slides v1.0.pdf\"\n",
        "running_on_colab = False\n",
        "\n",
        "try:\n",
        "    import gdown\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    print(\"Running in Google Colab. Using userdata to get HF_TOKEN.\")\n",
        "    # save locally from https://drive.google.com/file/d/1xUA6_ZBJzWGF7kWpM1YZTK3R1siYg1qY/view?usp=drive_link\n",
        "    gdown.download(id=\"1xUA6_ZBJzWGF7kWpM1YZTK3R1siYg1qY\", output=PDF_NAME, quiet=False)\n",
        "    running_on_colab = True\n",
        "except ModuleNotFoundError:\n",
        "    load_dotenv()\n",
        "    HF_TOKEN = os.getenv('HF_TOKEN')\n",
        "    print(\"Not running in Google Colab. Using load_dotenv to get HF_TOKEN.\")\n",
        "\n",
        "file_path = PDF_NAME\n",
        "login(token=HF_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_BeopoAvaimh"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Rimuovi formule matematiche LaTeX\n",
        "    text = re.sub(r'\\$.*?\\$', '', text)\n",
        "    # Rimuovi caratteri non alfanumerici eccetto punteggiatura di base\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s.,;:!?\\'\"-]', '', text)\n",
        "    # Rimuovi •\n",
        "    text = text.replace('•', '')\n",
        "    # Normalizza i caratteri Unicode\n",
        "    text = unidecode(text)\n",
        "    # Rimuovi spazi multipli\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def aggregate_short_documents(texts, min_length=50):\n",
        "    aggregated_texts = []\n",
        "    buffer = \"\"\n",
        "\n",
        "    for doc in texts:\n",
        "        if len(doc.page_content) < min_length:\n",
        "            buffer += \" \" + doc.page_content\n",
        "            buffer = buffer.strip()\n",
        "        else:\n",
        "            if buffer:\n",
        "                doc.page_content = buffer + \" \" + doc.page_content\n",
        "                buffer = \"\"\n",
        "            aggregated_texts.append(doc)\n",
        "\n",
        "    if buffer:\n",
        "        if aggregated_texts:\n",
        "            aggregated_texts[-1].page_content += \" \" + buffer\n",
        "        else:\n",
        "            aggregated_texts.append(buffer)\n",
        "\n",
        "    return aggregated_texts\n",
        "\n",
        "# ------------------------------------------------------------------------- #\n",
        "\n",
        "# Load and process the PDF\n",
        "loader = PyMuPDFLoader(file_path=file_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split the documents into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200, separator=\"\\n\")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Preprocess the text\n",
        "for doc in texts:\n",
        "    doc.page_content = preprocess_text(doc.page_content)\n",
        "\n",
        "# Aggrega i documenti corti\n",
        "corpus = aggregate_short_documents(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's give a look to some random documents extracted and preprocessed from the initial pdf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKx35jopaimh",
        "outputId": "a24cd6e7-b1f9-4cb8-d21c-2668782f3564"
      },
      "outputs": [],
      "source": [
        "# print some random pages with their indices\n",
        "random.seed(42)\n",
        "for i in range(5):\n",
        "    doc = random.choice(corpus)\n",
        "    doc_index = corpus.index(doc)\n",
        "    print(f\"DocId: {doc_index}, {doc.page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdh2ECCcaimi",
        "outputId": "352a4d3e-67e0-4084-94f5-23b4f153a3f2"
      },
      "outputs": [],
      "source": [
        "print(f\"Average document length: {sum(len(doc.page_content) for doc in corpus) / len(corpus)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also provide a `save_documents` function, which can be useful for further inspection of the PDF content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfIW-Bd6aimi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def save_documents(documents):\n",
        "    \"\"\"\n",
        "    Save the provided documents to the vector_store directory. Each document is saved as a separate text file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"vector_store\"):\n",
        "        os.makedirs(\"vector_store\")\n",
        "    # delete all files in the vector_store directory\n",
        "    for file in os.listdir(\"vector_store\"):\n",
        "        os.remove(os.path.join(\"vector_store\", file))\n",
        "    for i, doc in enumerate(documents):\n",
        "        with open(f\"vector_store/document_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVas_GFzaimi",
        "outputId": "5152224b-d952-4ce7-cd38-9f250a6414c4"
      },
      "outputs": [],
      "source": [
        "save_documents(corpus)\n",
        "print(f\"Saved {len(corpus)} documents in the vector_store directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR2e6XDsaimi",
        "outputId": "69c7e149-1825-49d6-d745-eca28d12f002"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def extract_questions(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    questions = []\n",
        "    for item in data:\n",
        "        # q = item.get(\"question\", \"\")\n",
        "        # a = item.get(\"answers\", \"\")\n",
        "        # # 'a' è una lista di stringhe, aggiungi ad ognuno 1, 2, 3, 4\n",
        "        # for i in range(len(a)):\n",
        "        #     a[i] = f\"{(1 + i)}) {a[i]}\"\n",
        "        # a = \" \".join(a)\n",
        "        # qplusa = f\"{q} {a}\"\n",
        "        if str(item.get(\"category\", \"\")) == \"1\":\n",
        "            continue\n",
        "        question = {\n",
        "            \"question\": item.get(\"question\", \"\").strip(),\n",
        "            # \"answers\": item.get(\"answers\", \"\"),\n",
        "            # \"correct\": item.get(\"correct\", \"\"),\n",
        "            # \"category\": item.get(\"category\", \"\"),\n",
        "            # \"question_id\": item.get(\"question_id\", \"\")\n",
        "        }\n",
        "        questions.append(question)\n",
        "    return questions\n",
        "\n",
        "\n",
        "file_path = \"quiz/quiz.json\"\n",
        "\n",
        "if running_on_colab:\n",
        "  if not os.path.exists(\"quiz\"):\n",
        "      os.makedirs(\"quiz\")\n",
        "  # save locally from https://drive.google.com/file/d/15pKNg7XwtaUILmxUhzhNa-ojTpqqLg__/view?usp=drive_link\n",
        "  gdown.download(id=\"15pKNg7XwtaUILmxUhzhNa-ojTpqqLg__\", output=file_path, quiet=False)\n",
        "\n",
        "queries = extract_questions(file_path)\n",
        "print(f\"Loaded {len(queries)} questions.\")\n",
        "\n",
        "random.seed(4242)\n",
        "print(random.choice(queries))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gather Dataset Embeddings\n",
        "\n",
        "In this first stage, the aim is to produce the documents embeddings, in order to be able to make similarity searches in the upcoming steps of the pipeline.\n",
        "\n",
        "### About the `cde-small-v1` Model\n",
        "\n",
        "The `cde-small-v1` model, developed by John X. Morris and Alexander M. Rush, is a cutting-edge model for generating **Contextual Document Embeddings (CDE)** ([link](https://huggingface.co/jxm/cde-small-v1)). What sets this model apart is its ability to integrate \"*context tokens*\" into the embedding process, which allows it to capture the nuances and relationships between documents more effectively. This makes it particularly suitable for generating highly accurate embeddings for both documents and queries, especially in cases where capturing the context of a document within the broader corpus is crucial.\n",
        "\n",
        "We chose this model because, as of December 2024, it is one of the leading models under 400M parameters, delivering impressive results on the [**Massive Text Embedding Benchmark (MTEB) leaderboard**](https://huggingface.co/spaces/mteb/leaderboard). Although it ranks 32nd overall, it stands out as the top model in terms of **memory efficiency**, which is a key factor for our project, given the requirement for **limited GPU capabilities**. Additionally, it offers a substantial **embedding dimension of 768**, striking a balance between computational efficiency and embedding quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sg3xXhiaimk"
      },
      "source": [
        "<style>\n",
        "    img {\n",
        "        border-radius: 15px;\n",
        "    }\n",
        "</style>\n",
        "![cde-small-v1.png](./assets/cde-small-v1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A key feature of the `cde-small-v1` model is its optimization for a two-stage embedding process:\n",
        "\n",
        "1. **First Stage**: Embedding a subset of documents from the corpus to create \"dataset embeddings,\" which serve as a **reference** for the entire corpus.\n",
        "2. **Second Stage**: Using the dataset embeddings to embed new queries and documents during inference.\n",
        "\n",
        "This model is compact yet delivers solid performance, making it suitable for our use case.\n",
        "\n",
        "### Steps to Gather Dataset Embeddings:\n",
        "\n",
        "1. **Selecting a Subset of Documents**  \n",
        "   We begin by sampling a representative set of documents from the corpus. Following the model's guidelines, we select 512 documents. If this number isn't available, the model can handle oversampling, which is the case for the PDF dataset we're using. Despite this, performance remains strong.\n",
        "\n",
        "2. **Generating Dataset Embeddings**  \n",
        "   After selecting the documents, we encode them using the `cde-small-v1` embedding model. This step produces dense vector representations of the documents, which are representative of the broader corpus.\n",
        "\n",
        "3. **Embedding Queries and Documents**  \n",
        "   Once the dataset embeddings are created, we use them to embed both documents and queries. A key feature of this model is its ability to differentiate between 'queries' and 'documents' during encoding, ensuring context is preserved during the embedding process.\n",
        "\n",
        "\n",
        "Next, we will load the model using the `SentenceTransformers` interface to begin the embedding process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# with sentence-transformers we don't need prefixes but, to do retrieval, we need to use prompt_name=\"query\" and prompt_name=\"document\" in the encode method of the model when embedding queries and documents, respectively.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# Load model at last revision\n",
        "# embeddings_model = SentenceTransformer(\n",
        "#     \"jxm/cde-small-v1\",\n",
        "#     trust_remote_code=True,\n",
        "#     revision=\"9e2ed1d8d569d34458913d2d246935c1b2324d11\",\n",
        "#     tokenizer_kwargs={\"revision\": \"86b5e0934494bd15c9632b12f734a8a67f723594\"}\n",
        "# ).to(device)\n",
        "\n",
        "embeddings_model = SentenceTransformer(\n",
        "    \"jxm/cde-small-v1\",\n",
        "    trust_remote_code=True,\n",
        "    cache_folder=\"./cache\"\n",
        "\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then let's follow up by producing the `minicorpus` (which is the subsample of the whole corpus) and what we called `dataset_embeddings`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ad99e9b42e5b4dfb86cbfb5e253226cf",
            "87e2b8d68130448d8b4c7e1223eb9043",
            "8a35259180534614bf2b592c9da5315b",
            "f814c4387ef14232a731aa69b1e89abd",
            "cf454408c83d4a2a9d5a0f4e8f2f6b59",
            "6f07c5d747bd47abae26ea69e259b8c3",
            "93fc3442fa2245079f6addc6f1774948",
            "8d5c4cb8f2734768aaa024cd21477761",
            "1832c91d4f42466185ae020fcbcb66c8",
            "a3439e9123e54445aa6c7db4bf5b694d",
            "dbe1c35c312d46d592fcf406e53c1e61"
          ]
        },
        "id": "7ISVKFnGaimk",
        "outputId": "aa773ab3-b184-42f4-c440-52d1d2840466"
      },
      "outputs": [],
      "source": [
        "minicorpus_size = embeddings_model[0].config.transductive_corpus_size # 512\n",
        "minicorpus_docs = random.choices(corpus, k=minicorpus_size) # oversampling is okay\n",
        "assert len(minicorpus_docs) == minicorpus_size # You must use exactly this many documents in the minicorpus. You can oversample if your corpus is smaller.\n",
        "\n",
        "dataset_embeddings = embeddings_model.encode(\n",
        "    [doc.page_content for doc in minicorpus_docs],\n",
        "    prompt_name=\"document\",\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "print(f\"Corpus size: {len(corpus)}\")\n",
        "print(f\"Computed embeddings for {len(minicorpus_docs)} documents. Shape: {dataset_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWDiKrp7aiml",
        "outputId": "b8af7e26-3d82-48ea-88b8-836e0125e857"
      },
      "outputs": [],
      "source": [
        "print(\"Some mini-corpus documents:\")\n",
        "\n",
        "# get some random documents from the minicorpus\n",
        "random.seed(4242)\n",
        "for i in random.sample(range(minicorpus_size), 5):\n",
        "    print(f\"document {i}: {minicorpus_docs[i].page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZLI5qjGaiml"
      },
      "source": [
        "Now that we have obtained the **dataset embeddings**, we can proceed to embed both documents and queries using the same model.\n",
        "\n",
        "To embed the documents and queries, we must ensure that we specify the correct `prompt_name` for each, as well as pass the `dataset_embeddings` to maintain context. The reason is that, as many state-of-the-art-models, this one was trained with task-specific prefixes:\n",
        "\n",
        "- For documents, use:  \n",
        "  `prompt_name=\"document\"`\n",
        "\n",
        "- For queries, use:  \n",
        "  `prompt_name=\"query\"`\n",
        "\n",
        "We also have to always additionally, specify  the `dataset_embeddings`, in order to use the once we produced before.\n",
        "\n",
        "By doing so, we ensure that the embeddings are generated with the correct context for both retrieval and generation tasks, leveraging the efficient performance of the `cde-small-v1` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "d51706e6c5374ec0a2e25f685a78ab23",
            "d7ce41c350944e088beaf67ac1626e68",
            "a7c56aeb04f54c949d24be5aa7385a41",
            "4cf4be41d2b344309c20462efcbb78d9",
            "2439997404344ce8a1f82bcdee4640c5",
            "190374648cb04974b5695cb998712cfe",
            "46483f824174468d8d8a6cc4ec57fba4",
            "404eebebf495495f824ab6ce1d1bf895",
            "e525fdfc27e846c2b8d649f0309dcc20",
            "6a47bbc78e9e4ea68dd9e068992082fd",
            "4f4532d51b2340998d415ea06b0cd416",
            "4cfeb1e0eadc4c858060dde3f2ca7d30",
            "c5ff974eba2446dda1959296162643fe",
            "619f07a3135445baba917e9f3e67b1d1",
            "d84ed787ae7644e69aced75c87a50710",
            "41b6eb642d594479aefa9b0707f8a7bf",
            "2b7ee9555e314b0b8de24fb54aa8fcb7",
            "07c7db682d6f44ab86a78242dc085da6",
            "70b2aad2644e46e195eeb6d576145eff",
            "ba1c74c6a56a41a0b89dc5b3eef89d41",
            "60c0afc75d634c2583db8c97590160f8",
            "78bf7b6be24d4d219bdbb9ca9619c12a"
          ]
        },
        "id": "Z-4WdCtLaiml",
        "outputId": "48d771b9-c42b-4d71-e629-9155c4148870"
      },
      "outputs": [],
      "source": [
        "doc_embeddings = embeddings_model.encode(\n",
        "    [doc.page_content for doc in corpus],\n",
        "    prompt_name=\"document\",\n",
        "    dataset_embeddings=dataset_embeddings, # this is the contexualized embeddings of the minicorpus\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "query_embeddings = embeddings_model.encode(\n",
        "    [query['question'] for query in queries],\n",
        "    prompt_name=\"query\",\n",
        "    dataset_embeddings=dataset_embeddings,  # this is the contexualized embeddings of the minicorpus\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "print(f\"Document embeddings shape: {doc_embeddings.shape}\")\n",
        "print(f\"Query embeddings shape: {query_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now computes similarities between the embeddings and all the queries by simply calling `embeddings_model.similarity` (which uses by default cosine similarity), and inspect some of the results obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8coT3HV9aiml",
        "outputId": "2cc1d3ff-63da-4bfb-940c-a78f15c1dc21"
      },
      "outputs": [],
      "source": [
        "similarities = embeddings_model.similarity(query_embeddings, doc_embeddings)\n",
        "print(\"'similarities' shape : \",similarities.shape)\n",
        "topk_values, topk_indices = similarities.topk(5)\n",
        "\n",
        "random.seed(4242)\n",
        "random_queries = random.sample(queries, 2)\n",
        "for query in random_queries:\n",
        "    query_idx = queries.index(query)\n",
        "    print(f\"Query: {query['question']}\")\n",
        "    for j, idx in enumerate(topk_indices[query_idx]):\n",
        "        doc = corpus[idx]\n",
        "        print(f\"Rank {j+1} (Score: {topk_values[query_idx][j]:.4f}, Doc ID: {idx}): {doc.page_content[:200]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH3wLZDIaiml"
      },
      "source": [
        "## Chroma\n",
        "\n",
        "Even if not necessary, ... TODO : scrivi che chroma lo abbiamo aggiunto perchè usare un DB per documenti grossi (che quindi produirranno tanti documenti quindi tanti embeddings) può essere una buona strategia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jszrG73aimm",
        "outputId": "14804cc1-d74e-48fa-8a83-3c6a68e44c33"
      },
      "outputs": [],
      "source": [
        "from chromadb import Client, Collection\n",
        "\n",
        "# Initialize the Chroma client\n",
        "client = Client()\n",
        "\n",
        "COLLECTION_NAME = \"chroma-collection\"\n",
        "\n",
        "# Check if the collection exists and delete it if it does\n",
        "if COLLECTION_NAME in [col.name for col in client.list_collections()]:\n",
        "    client.delete_collection(name=COLLECTION_NAME)\n",
        "    print(f\"Collection {COLLECTION_NAME} exists, deleting it\")\n",
        "else:\n",
        "    print(f\"Collection {COLLECTION_NAME} does not exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lGg8Ljrqaimm"
      },
      "outputs": [],
      "source": [
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "\n",
        "class CustomEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(self, mode=\"document\"):\n",
        "        self.mode = mode  # \"document\" or \"query\"\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "\n",
        "        # se input è una lista di documenti, estrai il testo\n",
        "        if isinstance(input, list):\n",
        "            input = [doc if isinstance(doc, str) else doc.page_content for doc in input]\n",
        "\n",
        "        # Genera embeddings usando il modello specifico\n",
        "        embeddings = embeddings_model.encode(\n",
        "            input,\n",
        "            prompt_name=self.mode,\n",
        "            dataset_embeddings=dataset_embeddings,\n",
        "            convert_to_tensor=True,\n",
        "            show_progress_bar=True\n",
        "        ).cpu().numpy()\n",
        "\n",
        "        return embeddings.tolist()\n",
        "\n",
        "# Create an instance of the embeddings function for queries (we already calculated all the embeddings of the documents)\n",
        "query_embeddings_function = CustomEmbeddingFunction(mode=\"query\")\n",
        "\n",
        "# Create a Chroma collection with the custom embedding function\n",
        "collection: Collection = client.create_collection(\n",
        "    name=COLLECTION_NAME,\n",
        "    embedding_function=query_embeddings_function,\n",
        "    get_or_create=True,\n",
        "    metadata={\"hnsw:space\": \"cosine\"} # l2 is the default but cosine is more suitable for this embedding function\n",
        ")\n",
        "\n",
        "# Add the documents and their (already computed) embeddings to the collection\n",
        "collection.add(\n",
        "    ids=[str(i) for i in range(len(corpus))],  # Unique identifiers for the documents\n",
        "    embeddings=doc_embeddings.cpu().numpy(),\n",
        "    documents=[doc.page_content for doc in corpus],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGxEGrC9aimm",
        "outputId": "994bf9d3-5c00-417f-f30f-cb4b48ff933d"
      },
      "outputs": [],
      "source": [
        "#print(collection.peek()) # returns a list of the first 10 items in the collection\n",
        "print(collection.count()) # returns the number of items in the collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![chroma-similarity-measures.png](./assets/chroma-similarity-measures.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "709f56f80e044a0eb971df7f7c773892",
            "981f60aa0cd24bbdb0479049b1677e50",
            "7e559406b8cc4632822471630624359b",
            "ae5634a9d847407e9ec321896e87bf52",
            "41d187d02e8c4d24a80db7455074fcc4",
            "ba305833dd1e4d6e8496bdcd9846aae7",
            "4e739abca4e044b0a0850030ee4b23c9",
            "af6603c8c0d44f4ba8022b514efa923d",
            "6b6d505d75d14aa0b8a6d1ddbd5309f0",
            "f7c90ec7921b4dbfa1ae668e4ddfdf9d",
            "b8a696376d8248f1bb0292a2b02c6981"
          ]
        },
        "id": "iwXd0aw1aimn",
        "outputId": "01d6474f-ccc1-49e5-d8b9-4d1c985e6321"
      },
      "outputs": [],
      "source": [
        "query_text = \"How many bytes can UTF-8 use to encode a character?\"\n",
        "\n",
        "results = collection.query(\n",
        "    query_texts=query_text,\n",
        "    n_results=5\n",
        ")\n",
        "print(results)\n",
        "\n",
        "# Print the results with the document IDs and scores\n",
        "for i, (doc_id, score, doc) in enumerate(zip(results['ids'][0], results['distances'][0], results['documents'][0])):\n",
        "    print(f\"Rank {i+1}: Document ID: {doc_id}, Score: {1-score:.4f}, {doc[:200]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckTwJIF5aimn"
      },
      "source": [
        "## 3. Compute scores between queries and documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "u4zQUCwaaimn",
        "outputId": "84a670c0-d802-4623-8a9c-592c65a77451"
      },
      "outputs": [],
      "source": [
        "from seaborn import heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot heatmap\n",
        "heatmap(similarities.cpu().numpy().T, cmap=\"jet\", ax=axes[0])\n",
        "axes[0].set_title(\"Similarity Heatmap\")\n",
        "\n",
        "# Plot histogram\n",
        "axes[1].hist(similarities.cpu().flatten(), bins=50, color='blue', alpha=0.6)\n",
        "axes[1].set_title(\"Distribution of Similarity Scores\")\n",
        "axes[1].set_xlabel(\"Similarity\")\n",
        "axes[1].set_ylabel(\"Frequency\")\n",
        "axes[1].axvline(x=0.5, color='red', alpha=0.6, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bxLzRQCaimn"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After conducting some research, we chose to work with one of Meta's latest smaller open-source Llama models available at the time of writing this notebook: [Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct), released the *25th of September 2024*. We specifically selected the *instruct* variant because it is pre-trained to follow basic instructions, offering a more user-friendly and fine-tuned experience compared to the standard non-instruct version (which is also available). Below, we review this model's [specifications](https://llamaimodel.com/requirements-3-2/):\n",
        "\n",
        "| **Llama 3.2 3B Instruct Model Specifications**                    | **Requirement**       | **Details**                                                                                  |\n",
        "|----------------------------------|-----------------------|----------------------------------------------------------------------------------------------|\n",
        "| Parameters                       | 3 billion             |                                                                                              |\n",
        "| Context Length                   | 128,000 tokens        |                                                                                              |\n",
        "| **Hardware Requirements**        |                       |                                                                                              |\n",
        "| CPU and RAM                      |                       | CPU: Multicore processor <br> RAM: Minimum of 16 GB recommended                              |\n",
        "| GPU                              |                       | NVIDIA RTX series (for optimal performance), at least 8 GB VRAM                              |\n",
        "| **Estimated GPU Memory Requirements** |                       |                                                                                              |\n",
        "| Higher Precision Modes           | BF16/FP16             | ~6.5 GB                                                                                      |\n",
        "| Lower Precision Modes            | FP8                   | ~3.2 GB                                                                                      |\n",
        "|                                  | INT4                  | ~1.75 GB                                                                                     |\n",
        "| **Software Requirements**        |                       |                                                                                              |\n",
        "| Software Dependencies            |                       | Frameworks: PyTorch <br> Libraries: Hugging Face Transformers (version 4.45.0 or higher), CUDA |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Is bf16 supported: \",torch.cuda.is_bf16_supported())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `bitsandbytes` library is a lightweight Python wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and 8 & 4-bit quantization functions.\n",
        "\n",
        "The library includes quantization primitives for 8-bit & 4-bit operations, through `bitsandbytes.nn.Linear8bitLt` and `bitsandbytes.nn.Linear4bit` and 8-bit optimizers through bitsandbytes.optim module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quantization Choices\n",
        "\n",
        "We chose a *middle ground* by loading the model with **4-bit quantization** while maintaining **BFloat16** precision for computation.\n",
        "\n",
        "The use of 4-bit quantization reduces the precision of the model’s weights to just 4 bits per value, significantly lowering memory usage and accelerating inference. This method retains only the most essential information, sacrificing some numerical precision, but allows for larger models to be handled on GPUs with limited memory. Despite the weights being quantized to 4 bits, the model still performs computations in **16-bit floating point (BFloat16)** precision. BFloat16 is a 16-bit format that preserves much of the dynamic range of floating-point operations while requiring less memory than the traditional 32-bit format. This way, while the 4-bit quantization reduces the memory footprint of the model weights, the computation is performed in BFloat16, optimizing performance on modern GPUs that are tailored for BFloat16 operations. This configuration strikes a balance between computational efficiency and numerical precision, enabling fast inferences with minimal memory usage without significant loss in result quality.\n",
        "\n",
        "Given the hardware constraints, we opted for **4-bit quantization** using `BitsAndBytes` (as explained later). This approach greatly reduces the memory footprint and speeds up inference, ensuring acceptable performance for our use case. Without this configuration, the GPU’s memory usage was consistently at 100%, and inference times were approximately 2-3 minutes per query. With 4-bit quantization, memory usage drops to about 6GB, preventing GPU overload and reducing inference time to around 30 seconds per query, delivering satisfactory results. Further details on the quantization process will be provided later.\n",
        "\n",
        "However, we also need to consider that both the embedding model and the LLM must be loaded into memory, which adds another layer of complexity to the memory management. This requires careful balancing, as the total memory usage must accommodate both the LLM and the embedding model simultaneously. We will address how we manage this in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d0a33414ea4e478091e2a845922f94df",
            "1f098a8605bb4e53a2202a609fc01a0c",
            "a12a5559bd5a4f35989bbc3193931353",
            "67070a50552249d6ae529d0a7ed5cec4",
            "fb3f41dbc1e9411f9c270dce6d96d9ad",
            "7e830c82ac25416bbdaf2150c9f5cea9",
            "90fb30f34b3a4016abc79346dbf591e1",
            "60ac5926bdb7443cac0d4f174500139e",
            "a40d112df596467caad3a65499772e16",
            "fb63777d4b20418dbb295fc3da69145c",
            "8110a4034b404052b3e063c9f4f5b655"
          ]
        },
        "id": "bnpvz_Wxaimn",
        "outputId": "1bcb10f1-4c33-4303-ba2b-9a33ba20f2c6"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # TODO : riguardare che fa\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "# Quantization is a technique that reduces the precision of\n",
        "# the model’s weights to make it run faster and consume less memory,\n",
        "# often at the cost of a slight reduction in model accuracy or quality\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                      # Lower precision reduces memory usage and can speed up inference (maybe try 8)\n",
        "    bnb_4bit_use_double_quant=True,         # Using double quantization can help reduce the loss in accuracy associated with quantization\n",
        "    bnb_4bit_quant_type=\"nf4\",              # Normal Float 4-bit quantization, a scheme that may preserve model quality better than straightforward quantization methods\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,  # The internal compute dtype used during inference. bfloat16 (BF16) is often chosen because it’s efficient on modern accelerators\n",
        "    llm_int8_enable_fp32_cpu_offload=True   # Enable FP32 CPU offload\n",
        ")\n",
        "\n",
        "\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map={\"\": device},  # Custom device map to ensure all modules are on GPU\n",
        "    quantization_config=bnb_config,\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "generation_config = llm_model.generation_config\n",
        "generation_config.max_new_tokens = 200                    # the maximum number of new tokens the model will generate (long outputs might be more prone to off-topic or repetitive content)\n",
        "generation_config.min_new_tokens = 1                      # the minimum number of new tokens the model will generate\n",
        "generation_config.temperature = 0.1                       # it controls the randomness of the generation, lower temp means more deterministic, conservative (less creative) and repetitive answers [about 0.1-1.2]\n",
        "generation_config.top_p = 0.5                             # nucleus sampling controls how the model picks words based on their cumulative probability, lower value (0.5) means safer, more coherent text but less diverse [about 0.5-0.9]\n",
        "generation_config.num_return_sequences = 1                # how many separate output sequences are returned for each generation prompt, get multiple different answers in one go, useful for picking the best response from several tries\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id   # special token IDs that represent padding and the end-of-sequence token. Generally, these are set to ensure the model knows when to stop and how to handle inputs of different lengths\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id\n",
        "generation_config.repetition_penalty = 2.0                # discourages the model from repeating the same phrases or tokens over and over [about 1.0-2.0] (high value cause the model to avoid some tokens even if they are contextually appropriate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU usage\n",
        "gpu_memory_gb = torch.cuda.get_device_properties(device).total_memory / (1024 ** 3)  # in GB\n",
        "memory_allocated_gb = torch.cuda.memory_allocated(device) / (1024 ** 3)  # in GB\n",
        "print(f\"Memory Allocated: {memory_allocated_gb:.2f} GB\")\n",
        "print(f\"Total memory usage: {(memory_allocated_gb / gpu_memory_gb) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "6a0c174b58a14a05a9827fe2ae956cce",
            "c91bc688fb1140db9c2300f9500944e0",
            "7fb96c3d08c34139a682c111f4d86658",
            "a1b2a34b1b7c4b78a9312ed5ab9c297e",
            "c0c360fa83be47b89c0a37fa29cfae71",
            "719b4e7a03aa49a3a74164b17e48995b",
            "e3dd4f7ae0ad41af81976a2f988e5a22",
            "007a80af9d124bfa8270e8798b1f161e",
            "5b0a3c9844c6448db067c3822fbb3655",
            "4003845ebb684b0abd3b5dd046ceca86",
            "e8daff5aa3604205a241f8ce3549abd5"
          ]
        },
        "id": "UTIj3ob0aimn",
        "outputId": "934f102b-89fe-4b43-884d-dacde2ee685f"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_documents(query, k=5):\n",
        "    results = collection.query( # query the Chroma collection\n",
        "        query_texts=query,\n",
        "        n_results=k\n",
        "    )\n",
        "    return results['documents'][0], results['distances'][0]\n",
        "\n",
        "# test the function\n",
        "query = \"How many bytes can UTF-8 use to encode a character?\"\n",
        "print(f\"Query: {query}\")\n",
        "documents, distances = retrieve_relevant_documents(query)\n",
        "for doc, distance in (zip(documents, distances)):\n",
        "    print(f\"(score: {1-distance:.4f}) {doc[:200]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dZoEEO3caimo"
      },
      "outputs": [],
      "source": [
        "base_prompt = \"\"\"You are an AI assistant for RAG. Your task is to understand the user question, and provide an answer using the provided contexts.\n",
        "\n",
        "Your answers are correct, high-quality, and written by a domain expert. If the provided context does not contain the answer, simply state, \"The provided context does not have the answer.\"\n",
        "\n",
        "User question: {user_query}\n",
        "\n",
        "Contexts:\n",
        "{chunks_information}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eykUFrE-aimo"
      },
      "outputs": [],
      "source": [
        "# Example usage of the RAG system with the PDF\n",
        "def answer_questions(questions):\n",
        "    count = 0\n",
        "    error = 0\n",
        "    results = {}\n",
        "\n",
        "    current_time = time.strftime(\"%m%d-%H%M%S\")\n",
        "\n",
        "    pbar = tqdm(questions, total=len(questions), desc=\"Answering questions...\", unit=\"question\")\n",
        "    for q in pbar:\n",
        "        top_k_chunks = retrieve_relevant_documents(q['question'], k=5)\n",
        "        retrieved_chunks = [chunk for chunk in top_k_chunks]\n",
        "        prompt = base_prompt.format(user_query=q['question'], chunks_information=\"\\n\".join(retrieved_chunks))\n",
        "        encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "        with torch.inference_mode():\n",
        "            outputs = llm_model.generate(\n",
        "                input_ids=encoding.input_ids,\n",
        "                attention_mask=encoding.attention_mask,\n",
        "                generation_config=generation_config,\n",
        "                num_beams=5,  # Use beam search for better results\n",
        "                early_stopping=True,  # Stop early if all beams finish\n",
        "            )\n",
        "\n",
        "        # Exclude the prompt tokens from the generated output\n",
        "        generated_tokens = outputs[0][len(encoding.input_ids[0]):]\n",
        "        generated_unpreprocessed_sequence = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "        match = re.search(r'\\b[1-4]\\b', generated_unpreprocessed_sequence)\n",
        "        answer = match.group(0) if match else \"\"  # first number found or empty string\n",
        "\n",
        "        with open(f\"quiz/runs_basemodel/quiz_answers_{current_time}.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Question: {q['question']}\\nAnswer: {answer}\\nCorrect answer:{q['correct']}\\nGenerated unpreprocessed sequence: {generated_unpreprocessed_sequence}\\n--------------------------------------------------------------------\\n\\n\")\n",
        "\n",
        "        results[q['question_id']] = answer\n",
        "\n",
        "        if len(answer) != 1 or answer not in \"1234\":\n",
        "            error += 1\n",
        "        else:  # the format is correct, now check if the answer is correct\n",
        "            if str(q['correct']) == answer:\n",
        "                count += 1\n",
        "        pbar.set_postfix(Corrects=f\"{count}/{len(questions)}\", Errors=error)\n",
        "\n",
        "    print(\"-------------------------\\tFINISHED RUN. Error count: \", error, \"-------------------------\")\n",
        "    return results, count / len(questions) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "Qffn8GFeaimo",
        "outputId": "f38e06b9-918d-4445-b07f-107f5d253a9d"
      },
      "outputs": [],
      "source": [
        "def query_rag_model(user_query):\n",
        "    documents, distances = retrieve_relevant_documents(user_query, k=5) # retrieve the top 5 most relevant documents\n",
        "    print(f\"Number of retrieved documents: {len(documents)}\")    \n",
        "    # Print the results\n",
        "    for doc, distance in zip(documents, distances):\n",
        "        print(f\"(score: {1-distance:.4f}) {doc[:200]}\")\n",
        "    prompt = base_prompt.format(user_query=user_query, chunks_information=\"\\n\".join(documents))\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        outputs = llm_model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "            num_beams=5,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "    generated_tokens = outputs[0][len(encoding.input_ids[0]):]\n",
        "    generated_unpreprocessed_sequence = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "    print(f\"Generated sequence: {generated_unpreprocessed_sequence}\")\n",
        "    return generated_unpreprocessed_sequence\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=query_rag_model,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"RAG Model Query Interface\",\n",
        "    description=\"Ask questions to the RAG model and get answers based on the provided PDF context.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "02qeKuldaimp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "007a80af9d124bfa8270e8798b1f161e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c7db682d6f44ab86a78242dc085da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1832c91d4f42466185ae020fcbcb66c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "190374648cb04974b5695cb998712cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f098a8605bb4e53a2202a609fc01a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e830c82ac25416bbdaf2150c9f5cea9",
            "placeholder": "​",
            "style": "IPY_MODEL_90fb30f34b3a4016abc79346dbf591e1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2439997404344ce8a1f82bcdee4640c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7ee9555e314b0b8de24fb54aa8fcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4003845ebb684b0abd3b5dd046ceca86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404eebebf495495f824ab6ce1d1bf895": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b6eb642d594479aefa9b0707f8a7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d187d02e8c4d24a80db7455074fcc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46483f824174468d8d8a6cc4ec57fba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf4be41d2b344309c20462efcbb78d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a47bbc78e9e4ea68dd9e068992082fd",
            "placeholder": "​",
            "style": "IPY_MODEL_4f4532d51b2340998d415ea06b0cd416",
            "value": " 10/10 [00:15&lt;00:00,  1.56s/it]"
          }
        },
        "4cfeb1e0eadc4c858060dde3f2ca7d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5ff974eba2446dda1959296162643fe",
              "IPY_MODEL_619f07a3135445baba917e9f3e67b1d1",
              "IPY_MODEL_d84ed787ae7644e69aced75c87a50710"
            ],
            "layout": "IPY_MODEL_41b6eb642d594479aefa9b0707f8a7bf"
          }
        },
        "4e739abca4e044b0a0850030ee4b23c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f4532d51b2340998d415ea06b0cd416": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b0a3c9844c6448db067c3822fbb3655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60ac5926bdb7443cac0d4f174500139e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c0afc75d634c2583db8c97590160f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "619f07a3135445baba917e9f3e67b1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70b2aad2644e46e195eeb6d576145eff",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba1c74c6a56a41a0b89dc5b3eef89d41",
            "value": 2
          }
        },
        "67070a50552249d6ae529d0a7ed5cec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb63777d4b20418dbb295fc3da69145c",
            "placeholder": "​",
            "style": "IPY_MODEL_8110a4034b404052b3e063c9f4f5b655",
            "value": " 2/2 [00:30&lt;00:00, 13.78s/it]"
          }
        },
        "6a0c174b58a14a05a9827fe2ae956cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c91bc688fb1140db9c2300f9500944e0",
              "IPY_MODEL_7fb96c3d08c34139a682c111f4d86658",
              "IPY_MODEL_a1b2a34b1b7c4b78a9312ed5ab9c297e"
            ],
            "layout": "IPY_MODEL_c0c360fa83be47b89c0a37fa29cfae71"
          }
        },
        "6a47bbc78e9e4ea68dd9e068992082fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b6d505d75d14aa0b8a6d1ddbd5309f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f07c5d747bd47abae26ea69e259b8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "709f56f80e044a0eb971df7f7c773892": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_981f60aa0cd24bbdb0479049b1677e50",
              "IPY_MODEL_7e559406b8cc4632822471630624359b",
              "IPY_MODEL_ae5634a9d847407e9ec321896e87bf52"
            ],
            "layout": "IPY_MODEL_41d187d02e8c4d24a80db7455074fcc4"
          }
        },
        "70b2aad2644e46e195eeb6d576145eff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719b4e7a03aa49a3a74164b17e48995b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78bf7b6be24d4d219bdbb9ca9619c12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e559406b8cc4632822471630624359b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6603c8c0d44f4ba8022b514efa923d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b6d505d75d14aa0b8a6d1ddbd5309f0",
            "value": 1
          }
        },
        "7e830c82ac25416bbdaf2150c9f5cea9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb96c3d08c34139a682c111f4d86658": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007a80af9d124bfa8270e8798b1f161e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b0a3c9844c6448db067c3822fbb3655",
            "value": 1
          }
        },
        "8110a4034b404052b3e063c9f4f5b655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e2b8d68130448d8b4c7e1223eb9043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f07c5d747bd47abae26ea69e259b8c3",
            "placeholder": "​",
            "style": "IPY_MODEL_93fc3442fa2245079f6addc6f1774948",
            "value": "Batches: 100%"
          }
        },
        "8a35259180534614bf2b592c9da5315b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d5c4cb8f2734768aaa024cd21477761",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1832c91d4f42466185ae020fcbcb66c8",
            "value": 16
          }
        },
        "8d5c4cb8f2734768aaa024cd21477761": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fb30f34b3a4016abc79346dbf591e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93fc3442fa2245079f6addc6f1774948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981f60aa0cd24bbdb0479049b1677e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba305833dd1e4d6e8496bdcd9846aae7",
            "placeholder": "​",
            "style": "IPY_MODEL_4e739abca4e044b0a0850030ee4b23c9",
            "value": "Batches: 100%"
          }
        },
        "a12a5559bd5a4f35989bbc3193931353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ac5926bdb7443cac0d4f174500139e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a40d112df596467caad3a65499772e16",
            "value": 2
          }
        },
        "a1b2a34b1b7c4b78a9312ed5ab9c297e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4003845ebb684b0abd3b5dd046ceca86",
            "placeholder": "​",
            "style": "IPY_MODEL_e8daff5aa3604205a241f8ce3549abd5",
            "value": " 1/1 [00:00&lt;00:00, 16.70it/s]"
          }
        },
        "a3439e9123e54445aa6c7db4bf5b694d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40d112df596467caad3a65499772e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7c56aeb04f54c949d24be5aa7385a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404eebebf495495f824ab6ce1d1bf895",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e525fdfc27e846c2b8d649f0309dcc20",
            "value": 10
          }
        },
        "ad99e9b42e5b4dfb86cbfb5e253226cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87e2b8d68130448d8b4c7e1223eb9043",
              "IPY_MODEL_8a35259180534614bf2b592c9da5315b",
              "IPY_MODEL_f814c4387ef14232a731aa69b1e89abd"
            ],
            "layout": "IPY_MODEL_cf454408c83d4a2a9d5a0f4e8f2f6b59"
          }
        },
        "ae5634a9d847407e9ec321896e87bf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c90ec7921b4dbfa1ae668e4ddfdf9d",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a696376d8248f1bb0292a2b02c6981",
            "value": " 1/1 [00:00&lt;00:00, 18.46it/s]"
          }
        },
        "af6603c8c0d44f4ba8022b514efa923d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a696376d8248f1bb0292a2b02c6981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba1c74c6a56a41a0b89dc5b3eef89d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba305833dd1e4d6e8496bdcd9846aae7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c360fa83be47b89c0a37fa29cfae71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ff974eba2446dda1959296162643fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b7ee9555e314b0b8de24fb54aa8fcb7",
            "placeholder": "​",
            "style": "IPY_MODEL_07c7db682d6f44ab86a78242dc085da6",
            "value": "Batches: 100%"
          }
        },
        "c91bc688fb1140db9c2300f9500944e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719b4e7a03aa49a3a74164b17e48995b",
            "placeholder": "​",
            "style": "IPY_MODEL_e3dd4f7ae0ad41af81976a2f988e5a22",
            "value": "Batches: 100%"
          }
        },
        "cf454408c83d4a2a9d5a0f4e8f2f6b59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0a33414ea4e478091e2a845922f94df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f098a8605bb4e53a2202a609fc01a0c",
              "IPY_MODEL_a12a5559bd5a4f35989bbc3193931353",
              "IPY_MODEL_67070a50552249d6ae529d0a7ed5cec4"
            ],
            "layout": "IPY_MODEL_fb3f41dbc1e9411f9c270dce6d96d9ad"
          }
        },
        "d51706e6c5374ec0a2e25f685a78ab23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7ce41c350944e088beaf67ac1626e68",
              "IPY_MODEL_a7c56aeb04f54c949d24be5aa7385a41",
              "IPY_MODEL_4cf4be41d2b344309c20462efcbb78d9"
            ],
            "layout": "IPY_MODEL_2439997404344ce8a1f82bcdee4640c5"
          }
        },
        "d7ce41c350944e088beaf67ac1626e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190374648cb04974b5695cb998712cfe",
            "placeholder": "​",
            "style": "IPY_MODEL_46483f824174468d8d8a6cc4ec57fba4",
            "value": "Batches: 100%"
          }
        },
        "d84ed787ae7644e69aced75c87a50710": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60c0afc75d634c2583db8c97590160f8",
            "placeholder": "​",
            "style": "IPY_MODEL_78bf7b6be24d4d219bdbb9ca9619c12a",
            "value": " 2/2 [00:01&lt;00:00,  1.08it/s]"
          }
        },
        "dbe1c35c312d46d592fcf406e53c1e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3dd4f7ae0ad41af81976a2f988e5a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e525fdfc27e846c2b8d649f0309dcc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8daff5aa3604205a241f8ce3549abd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c90ec7921b4dbfa1ae668e4ddfdf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f814c4387ef14232a731aa69b1e89abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3439e9123e54445aa6c7db4bf5b694d",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe1c35c312d46d592fcf406e53c1e61",
            "value": " 16/16 [00:05&lt;00:00,  3.58it/s]"
          }
        },
        "fb3f41dbc1e9411f9c270dce6d96d9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb63777d4b20418dbb295fc3da69145c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
